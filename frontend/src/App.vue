<script setup lang="ts">
import { ref, onMounted, onBeforeUnmount } from 'vue'
import { useApi } from './composables/useApi'
import { useTTS } from './composables/useTTS'
import { usePermissions } from './composables/usePermissions'
import { useCamera } from './composables/useCamera'

type HealthState = 'idle' | 'loading' | 'ok' | 'error'

const capturedImageUrl = ref<string | null>(null)
const { videoEl, cameraReady, cameraError, startCamera, stopCamera, captureFrame } = useCamera()
const cameraActivated = ref(false)
const health = ref<HealthState>('idle')
// Speech recognition state
const recognizing = ref(false)
const transcript = ref<string>('')
const subtitles = ref<string[]>([])
const recognitionSupported = ref<boolean>(typeof window !== 'undefined' && (!!(window as any).SpeechRecognition || !!(window as any).webkitSpeechRecognition))
let recognition: any = null
let shouldKeepRecognizing = false
let debounceTimer: ReturnType<typeof setTimeout> | null = null
let pendingFinalText = ''
// Shopping mode state
const shoppingMode = ref(false)
let currentWish = ''
let wishDebounceTimer: ReturnType<typeof setTimeout> | null = null
// TTS / live region for accessibility
const liveMessage = ref<string>('')
// TTS composable
const { ttsReady, pickZhVoice, ensureTtsUnlocked, speakText } = useTTS()

// Recognition restart/backoff state
let restartAttempts = 0
const maxRestartAttempts = 6
const { micPermission, cameraPermission, refreshPermissionsFromDevices, checkMicPermission, checkCameraPermission, cleanupPermissionWatchers } = usePermissions()

// API helpers
const { checkBackendHealth: apiCheckHealth, analyze } = useApi()

if (recognitionSupported.value) {
  const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition
  recognition = new SpeechRecognition()
  // try to enable continuous; some implementations ignore it
  recognition.continuous = true
  recognition.lang = 'zh-TW'
  recognition.interimResults = true
  recognition.maxAlternatives = 1

  recognition.onstart = () => {
    recognizing.value = true
    // On many mobile browsers, Permissions API for microphone is unreliable
    // Mark mic as granted when recognition actually starts
    micPermission.value = 'granted'
  }

  recognition.onresult = (event: any) => {
    let interim = ''
    let final = ''
    for (let i = event.resultIndex; i < event.results.length; i++) {
      const res = event.results[i]
      if (res.isFinal) final += res[0].transcript
      else interim += res[0].transcript
    }
    
    // Update transcript with both final and interim for full display
    if (final.trim()) {
      transcript.value = (transcript.value + ' ' + final).trim()
      pendingFinalText = final.trim()

      // Keyword detection: shopping mode and related commands
      try {
        const text = final.trim()
        // é–‹å•Ÿé€›è¡—æ¨¡å¼
        if (!shoppingMode.value && (text.includes('é–‹å•Ÿé€›è¡—æ¨¡å¼') || text.includes('é–‹å§‹é€›è¡—æ¨¡å¼'))) {
          shoppingMode.value = true
          cameraActivated.value = true
          // start camera and immediately take photo and notify backend with action=open
          startCamera({ cameraPermissionRef: cameraPermission, refreshPermissionsFromDevices }).then(() => {
            setTimeout(() => {
              takePhotoAndSend('open', null)
            }, 500)
          })
        }

        // Detect user wants (start collecting after keyword æˆ‘æƒ³è¦)
        if (shoppingMode.value && text.includes('æˆ‘æƒ³è¦')) {
          const idx = text.indexOf('æˆ‘æƒ³è¦')
          const after = text.slice(idx + 3).trim()
          if (after) {
            currentWish += (currentWish ? ' ' : '') + after
          }
          if (wishDebounceTimer) clearTimeout(wishDebounceTimer)
          wishDebounceTimer = setTimeout(() => {
            if (currentWish.trim()) {
              takePhotoAndSend('shopping', currentWish.trim())
            }
            currentWish = ''
            wishDebounceTimer = null
          }, 1200)
        }

        // çµæŸé€›è¡—æ¨¡å¼
        if (shoppingMode.value && (text.includes('çµæŸé€›è¡—æ¨¡å¼') || text.includes('é›¢é–‹é€›è¡—æ¨¡å¼'))) {
          takePhotoAndSend('close', null)
          shoppingMode.value = false
          currentWish = ''
          if (wishDebounceTimer) { clearTimeout(wishDebounceTimer); wishDebounceTimer = null }
          stopCamera()
        }

        // ä¿ç•™åŸå…ˆé–‹å•Ÿæ‹ç…§æ¨¡å¼é—œéµå­—
        if (!cameraActivated.value && text.includes('é–‹å•Ÿæ‹ç…§æ¨¡å¼')) {
          cameraActivated.value = true
          startCamera({ cameraPermissionRef: cameraPermission, refreshPermissionsFromDevices })
        }
      } catch {}
      
      // Debounce subtitle updates - only add to subtitles after text is stable
      if (debounceTimer) clearTimeout(debounceTimer)
      debounceTimer = setTimeout(() => {
        if (pendingFinalText.trim()) {
          subtitles.value.push(pendingFinalText.trim())
          pendingFinalText = ''
        }
      }, 700)
    }
    
    // Show interim results only in transcript, not in subtitles
    if (interim.trim()) {
      // Don't modify transcript with interim to avoid duplication
      // Just let user see interim in real-time without adding to history
    }
  }

  recognition.onerror = (e: any) => {
    console.error('Speech recognition error', e)
  }

  recognition.onend = () => {
    recognizing.value = false
    
    // Flush any pending final text immediately when recognition ends
    if (debounceTimer) {
      clearTimeout(debounceTimer)
      debounceTimer = null
    }
    if (pendingFinalText.trim()) {
      subtitles.value.push(pendingFinalText.trim())
      pendingFinalText = ''
    }
    
    // Robust restart: only restart if requested; use backoff to avoid busy-loop failures
    if (shouldKeepRecognizing) {
      restartAttempts = Math.min(maxRestartAttempts, restartAttempts + 1)
      const backoffMs = Math.min(200 * Math.pow(2, restartAttempts - 1), 5000)
      setTimeout(() => {
        try {
          recognition.start()
          // success: reset attempts
          restartAttempts = 0
        } catch (e) {
          console.warn('restart recognition failed', e)
        }
      }, backoffMs)
    }
  }
}

function onTtsUnlockClick() {
  try {
    ensureTtsUnlocked()
    if (ttsReady.value) liveMessage.value = 'èªéŸ³å·²å•Ÿç”¨'
  } catch {}
}

async function takePhoto() {
  try {
    const frame = await captureFrame()
    if (!frame) return
    if (capturedImageUrl.value) URL.revokeObjectURL(capturedImageUrl.value)
    capturedImageUrl.value = frame.url
    await checkBackendHealth()
  } catch (e) {
    console.error('takePhoto failed', e)
  }
}

function backToCapture() {
  if (capturedImageUrl.value) URL.revokeObjectURL(capturedImageUrl.value)
  capturedImageUrl.value = null
  health.value = 'idle'
}

// helper: take photo blob and send to backend /gemini/analyze with action
async function takePhotoAndSend(action: string, text: string | null) {
  try {
    const frame = await captureFrame()
    if (!frame) return

    // update captured preview
    if (capturedImageUrl.value) URL.revokeObjectURL(capturedImageUrl.value)
    capturedImageUrl.value = frame.url

    health.value = 'loading'
    try {
      const data = await analyze(action, text, frame.blob)
      health.value = 'ok'
      console.log('analyze result', data)
      // announce result for accessibility
      const spoken = typeof data?.result === 'string' ? data.result : JSON.stringify(data.result)
      liveMessage.value = spoken
      speakText(spoken)
    } catch (e) {
      console.error('analyze failed', e)
      health.value = 'error'
      const errMsg = 'ä¼ºæœå™¨å›æ‡‰å¤±æ•—'
      liveMessage.value = errMsg
      speakText(errMsg)
    }
  } catch (e) {
    console.error('takePhotoAndSend failed', e)
  }
}

onMounted(() => {
  // Prepare TTS voices
  if ('speechSynthesis' in window) {
    try {
      pickZhVoice()
      window.speechSynthesis.onvoiceschanged = () => pickZhVoice()
    } catch {}
  }
  // Auto-start continuous speech recognition loop
  if (recognitionSupported.value) {
    shouldKeepRecognizing = true
    try {
      recognition.start()
    } catch (e) {
      setTimeout(() => {
        try { recognition.start() } catch {}
      }, 200)
    }
  }

  // Check microphone permission state
  checkMicPermission()
  // Check camera permission state
  checkCameraPermission()
  // Best-effort: try to infer permissions by checking labeled devices (works after first grant)
  setTimeout(() => { refreshPermissionsFromDevices() }, 300)
})

onBeforeUnmount(() => {
  stopCamera()
  cleanupPermissionWatchers()
})

function toggleRecognition() {
  if (!recognitionSupported.value) return
  if (micPermission.value === 'denied') {
    alert('éº¥å…‹é¢¨æ¬Šé™è¢«æ‹’çµ•ï¼Œè«‹è‡³ç€è¦½å™¨è¨­å®šé–‹å•Ÿéº¥å…‹é¢¨æ¬Šé™')
    return
  }
  if (recognizing.value) {
    // user requested stop
    shouldKeepRecognizing = false
    
    // Clean up debounce timer and flush pending text
    if (debounceTimer) {
      clearTimeout(debounceTimer)
      debounceTimer = null
    }
    if (pendingFinalText.trim()) {
      subtitles.value.push(pendingFinalText.trim())
      pendingFinalText = ''
    }
    
    recognition.stop()
  } else {
    // user requested start; enable keep-alive behavior
    shouldKeepRecognizing = true
    try {
      recognition.start()
    } catch (e) {
      console.warn('recognition start error', e)
      // sometimes recognition needs a tiny delay before starting
      setTimeout(() => {
        try { recognition.start() } catch (e) { console.warn('second start failed', e) }
      }, 200)
    }
  }
}

async function checkBackendHealth() {
  health.value = 'loading'
  try {
    const status = await apiCheckHealth()
    health.value = status === 'ok' ? 'ok' : 'error'
  } catch (e) {
    health.value = 'error'
  }
}

// checkMicPermission, checkCameraPermission provided by composable
</script>

<template>
  <main class="min-h-full grid grid-rows-[1fr_auto]">
    <!-- Live region for screen readers: announce API/TTS results -->
    <div class="sr-only" aria-live="polite">{{ liveMessage }}</div>
    <section class="p-4 pb-2 flex items-center justify-center">
      <div class="w-full max-w-sm">
        <!-- Speech transcript area -->
        <div class="mb-4">
          <div class="w-full rounded-2xl bg-neutral-100 dark:bg-neutral-900 p-4 text-center">
            <p class="text-sm opacity-80">èªéŸ³è¾¨è­˜</p>
            <p class="mt-2 text-base break-words" aria-live="polite">{{ transcript || 'å°šæœªè¾¨è­˜åˆ°èªéŸ³' }}</p>
            <p class="mt-2 text-xs opacity-70">
              éº¥å…‹é¢¨æ¬Šé™ï¼š
              <span :class="{
                'text-green-600': micPermission==='granted',
                'text-red-600': micPermission==='denied',
                'text-blue-600': micPermission==='prompt',
              }">
                {{ micPermission === 'unsupported' ? 'æœªçŸ¥/ä¸æ”¯æ´' : micPermission === 'granted' ? 'å·²å…è¨±' : micPermission === 'denied' ? 'å·²æ‹’çµ•' : 'ç­‰å¾…æˆæ¬Š' }}
              </span>
            </p>
            <p class="mt-1 text-xs opacity-70">
              ç›¸æ©Ÿæ¬Šé™ï¼š
              <span :class="{
                'text-green-600': cameraPermission==='granted',
                'text-red-600': cameraPermission==='denied',
                'text-blue-600': cameraPermission==='prompt',
              }">
                {{ cameraPermission === 'unsupported' ? 'æœªçŸ¥/ä¸æ”¯æ´' : cameraPermission === 'granted' ? 'å·²å…è¨±' : cameraPermission === 'denied' ? 'å·²æ‹’çµ•' : 'ç­‰å¾…æˆæ¬Š' }}
              </span>
            </p>
          </div>
        </div>
        <div v-if="cameraActivated" class="relative">
          <div class="aspect-[3/4] overflow-hidden rounded-2xl bg-neutral-200 dark:bg-neutral-800">
            <video ref="videoEl" playsinline muted class="w-full h-full object-cover"></video>
          </div>
          <p v-if="!cameraReady && !cameraError" class="absolute inset-0 grid place-items-center text-sm opacity-80">
            æ­£åœ¨é–‹å•Ÿç›¸æ©Ÿâ€¦
          </p>
          <p v-if="cameraError" class="mt-2 text-sm text-red-600">{{ cameraError }}</p>
        </div>
        <div v-else class="aspect-[3/4] rounded-2xl bg-neutral-200 dark:bg-neutral-800 flex items-center justify-center text-center p-4">
          <p class="text-sm opacity-80">èªéŸ³åµæ¸¬ä¸­â€¦ èªªã€Œé–‹å•Ÿæ‹ç…§æ¨¡å¼ã€ä»¥å•Ÿç”¨ç›¸æ©Ÿ</p>
        </div>

        <template v-if="capturedImageUrl">
          <div class="mt-3">
            <img :src="capturedImageUrl" alt="captured" class="w-full rounded-2xl object-cover aspect-[3/4]" />
          </div>
          <div class="mt-3 rounded-xl border border-neutral-200/70 dark:border-neutral-700 p-3 flex items-center justify-between bg-neutral-50 dark:bg-neutral-900">
            <div>
              <p class="text-sm opacity-70">å¾Œç«¯å¥åº·æª¢æŸ¥</p>
              <p class="text-base font-medium" :class="{
                'text-blue-600': health==='loading',
                'text-green-600': health==='ok',
                'text-red-600': health==='error',
              }">
                {{ health === 'idle' ? 'å°šæœªæª¢æŸ¥' : health === 'loading' ? 'æª¢æŸ¥ä¸­â€¦' : health === 'ok' ? 'é€£ç·šæ­£å¸¸' : 'é€£ç·šå¤±æ•—' }}
              </p>
            </div>
            <div class="flex items-center gap-2">
              <button class="h-10 px-4 rounded-lg bg-neutral-100 dark:bg-neutral-800 border border-neutral-200/70 dark:border-neutral-700 active:scale-[0.98]" @click="checkBackendHealth">
                é‡æ–°æª¢æŸ¥
              </button>
              <button class="h-10 px-3 rounded-lg bg-neutral-100 dark:bg-neutral-800 border border-neutral-200/70 dark:border-neutral-700 active:scale-[0.98]" @click="backToCapture">
                æ¸…é™¤æˆªåœ–
              </button>
            </div>
          </div>
        </template>
      </div>
    </section>

    <nav class="sticky bottom-0 p-4 grid grid-cols-3 gap-3">
      <!-- Large microphone button for accessibility -->
      <button
        class="col-span-3 h-20 rounded-full bg-red-600 text-white text-2xl shadow-md active:scale-[0.98] flex items-center justify-center"
        :aria-pressed="recognizing"
        :aria-label="recognitionSupported ? (recognizing ? 'åœæ­¢èªéŸ³è¾¨è­˜' : 'å•Ÿå‹•èªéŸ³è¾¨è­˜') : 'èªéŸ³è¾¨è­˜ä¸æ”¯æ´'"
        :disabled="!recognitionSupported"
        @click="toggleRecognition"
      >
        <span v-if="!recognitionSupported">ğŸ¤ ä¸æ”¯æ´</span>
        <span v-else>
          <span v-if="recognizing">åœ&nbsp;æ­¢</span>
          <span v-else>é–‹å§‹åµæ¸¬</span>
        </span>
      </button>

      <!-- One-time TTS unlock for mobile browsers -->
      <button
        v-if="!ttsReady"
        class="col-span-3 mt-2 h-12 rounded-lg bg-neutral-100 dark:bg-neutral-800 border border-neutral-200/70 dark:border-neutral-700 text-base active:scale-[0.98]"
        aria-label="å•Ÿç”¨èªéŸ³è¼¸å‡º"
        @click="onTtsUnlockClick"
      >
        å•Ÿç”¨èªéŸ³è¼¸å‡ºï¼ˆè‹¥æ‰‹æ©Ÿæ²’æœ‰èªªè©±è«‹å…ˆé»æˆ‘ï¼‰
      </button>

      <!-- Live region for screen readers (visually hidden) -->
      <div class="sr-only" aria-live="polite">{{ recognizing ? 'éº¥å…‹é¢¨å·²é–‹å•Ÿ' : 'éº¥å…‹é¢¨å·²é—œé–‰' }}</div>

      <!-- Subtitle sliding window (overlay at bottom) -->
      <div aria-hidden="false" class="col-span-3 pointer-events-none">
        <div class="subtitle-window fixed left-1/2 transform -translate-x-1/2 bottom-36 w-full max-w-2xl px-4">
          <div class="space-y-2">
            <div v-for="(s, idx) in subtitles.slice(-5)" :key="idx" class="subtitle-item">
              {{ s }}
            </div>
          </div>
        </div>
      </div>

      <button
        v-if="cameraActivated"
        class="col-span-3 h-14 rounded-full bg-blue-600 text-white text-lg shadow-md active:scale-[0.98] disabled:opacity-60"
        aria-label="æ‹ç…§"
        :disabled="!cameraReady || !!cameraError"
        @click="takePhoto"
      >
        æ‹ç…§
      </button>
    </nav>
  </main>
  
</template>

<style scoped>
.subtitle-window {
  display: flex;
  justify-content: center;
  align-items: flex-end;
  z-index: 60;
}
.subtitle-window .space-y-2 {
  display: flex;
  flex-direction: column-reverse;
  gap: 0.5rem;
  align-items: center;
}
.subtitle-item {
  background: rgba(0,0,0,0.75);
  color: white;
  padding: 0.5rem 1rem;
  border-radius: 0.5rem;
  font-size: 1.125rem;
  line-height: 1.2;
  max-width: 90%;
  text-align: center;
  box-shadow: 0 8px 24px rgba(0,0,0,0.3);
  pointer-events: none;
  animation: slideInUp 360ms cubic-bezier(.22,.9,.31,1) both;
}

@keyframes slideInUp {
  from {
    opacity: 0;
    transform: translateY(12px);
  }
  to {
    opacity: 1;
    transform: translateY(0);
  }
}
</style>
