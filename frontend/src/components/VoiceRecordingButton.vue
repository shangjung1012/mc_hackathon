<template>
  <div class="flex flex-col items-center">
    <!-- éŒ„éŸ³æŒ‰éˆ• -->
    <button
      @click="toggleRecording"
      :disabled="disabled"
      :class="[
        'w-32 h-32 rounded-full transition-all duration-300 transform hover:scale-105 active:scale-95 focus:outline-none focus:ring-4 focus:ring-opacity-50 flex items-center justify-center',
        isRecording 
          ? 'bg-red-500 hover:bg-red-600 focus:ring-red-300 shadow-lg shadow-red-200' 
          : 'bg-blue-500 hover:bg-blue-600 focus:ring-blue-300 shadow-lg shadow-blue-200',
        disabled ? 'opacity-50 cursor-not-allowed' : ''
      ]"
      :aria-label="isRecording ? 'åœæ­¢éŒ„éŸ³' : 'é–‹å§‹éŒ„éŸ³'"
    >
      <!-- ä¸‰è§’å½¢æ’­æ”¾åœ–æ¨™ -->
      <div v-if="!isRecording" class="w-0 h-0 border-l-[24px] border-l-white border-t-[18px] border-t-transparent border-b-[18px] border-b-transparent ml-2"></div>
      <!-- æ­£æ–¹å½¢åœæ­¢åœ–æ¨™ -->
      <div v-else class="w-8 h-8 bg-white rounded-sm"></div>
    </button>

    <!-- ç‹€æ…‹æ–‡å­— -->
    <p v-if="isRecording" class="mt-4 text-lg font-medium text-gray-700 dark:text-gray-300">
      éŒ„éŸ³ä¸­... é»æ“Šåœæ­¢
    </p>
    <p v-else-if="!disabled" class="mt-4 text-sm text-gray-600 dark:text-gray-400">
      é»æ“Šé–‹å§‹éŒ„éŸ³
    </p>

    <!-- éŒ„éŸ³æ™‚é–“é¡¯ç¤º -->
    <p v-if="isRecording" class="mt-2 text-sm text-gray-500 dark:text-gray-400">
      éŒ„éŸ³æ™‚é–“: {{ formatTime(recordingTime) }}
    </p>

    <!-- éŒ¯èª¤è¨Šæ¯ -->
    <p v-if="error" class="mt-4 text-red-500 text-sm text-center max-w-xs">
      {{ error }}
    </p>

    <!-- ç§»å‹•è¨­å‚™æ¬Šé™æŒ‡å¼• -->
    <div v-if="showMobileGuidance" class="mt-4 p-3 bg-blue-50 dark:bg-blue-900 rounded-lg text-sm text-blue-800 dark:text-blue-200">
      <p class="font-medium mb-2">ğŸ“± ç§»å‹•è¨­å‚™ä½¿ç”¨æŒ‡å¼•ï¼š</p>
      <ul class="text-left space-y-1">
        <li>â€¢ ç¢ºä¿ä½¿ç”¨ HTTPS è¨ªå•ï¼ˆå®‰å…¨é€£æ¥ï¼‰</li>
        <li>â€¢ é»æ“ŠéŒ„éŸ³æŒ‰éˆ•å¾Œå…è¨±éº¥å…‹é¢¨æ¬Šé™</li>
        <li>â€¢ å¦‚è¢«æ‹’çµ•ï¼Œè«‹åˆ°ç€è¦½å™¨è¨­å®šä¸­å…è¨±éº¥å…‹é¢¨</li>
        <li>â€¢ å»ºè­°ä½¿ç”¨ Chrome æˆ– Safari ç€è¦½å™¨</li>
      </ul>
    </div>
  </div>
</template>

<script setup lang="ts">
import { ref, onMounted, onUnmounted } from 'vue'

interface Props {
  disabled?: boolean
  onRecordingStart?: () => void
  onRecordingStop?: () => void
  onTranscript?: (transcript: string) => void
}

const props = withDefaults(defineProps<Props>(), {
  disabled: false
})

const emit = defineEmits<{
  recordingStart: []
  recordingStop: []
  transcript: [transcript: string]
  error: [error: string]
}>()

const isRecording = ref(false)
const mediaRecorder = ref<MediaRecorder | null>(null)
const recordingTime = ref(0)
const error = ref('')
const recordingInterval = ref<number | null>(null)
const speechRecognition = ref<any>(null)
const isListening = ref(false)
const showMobileGuidance = ref(false)

// æ ¼å¼åŒ–æ™‚é–“é¡¯ç¤º
const formatTime = (seconds: number): string => {
  const mins = Math.floor(seconds / 60)
  const secs = seconds % 60
  return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`
}

// åˆå§‹åŒ–èªéŸ³è­˜åˆ¥
const initializeSpeechRecognition = () => {
  if (!('SpeechRecognition' in window) && !('webkitSpeechRecognition' in window)) {
    error.value = 'æ­¤ç€è¦½å™¨ä¸æ”¯æ´èªéŸ³è­˜åˆ¥åŠŸèƒ½'
    return false
  }

  try {
    const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition
    speechRecognition.value = new SpeechRecognition()
    
    speechRecognition.value.lang = 'zh-TW'
    speechRecognition.value.continuous = true
    speechRecognition.value.interimResults = true
    speechRecognition.value.maxAlternatives = 1

    speechRecognition.value.onstart = () => {
      console.log('ğŸ¤ èªéŸ³è­˜åˆ¥é–‹å§‹')
      isListening.value = true
    }

    speechRecognition.value.onresult = (event: any) => {
      const result = event.results[event.resultIndex]
      const transcript = result[0].transcript
      const isFinal = result.isFinal

      console.log('ğŸ¤ VoiceRecordingButton èªéŸ³è­˜åˆ¥çµæœ:', { transcript, isFinal })

      if (isFinal) {
        console.log('âœ… ç™¼é€æœ€çµ‚è½‰æ–‡å­—çµæœ:', transcript)
        emit('transcript', transcript)
      }
    }

    speechRecognition.value.onerror = (event: any) => {
      isListening.value = false
      let errorMessage = 'èªéŸ³è­˜åˆ¥ç™¼ç”ŸéŒ¯èª¤'

      switch (event.error) {
        case 'no-speech':
          errorMessage = 'æ²’æœ‰æª¢æ¸¬åˆ°èªéŸ³ï¼Œè«‹é‡è©¦'
          break
        case 'audio-capture':
          errorMessage = 'ç„¡æ³•è¨ªå•éº¥å…‹é¢¨'
          break
        case 'not-allowed':
          errorMessage = 'éº¥å…‹é¢¨æ¬Šé™è¢«æ‹’çµ•'
          break
        case 'network':
          errorMessage = 'ç¶²è·¯é€£ç·šéŒ¯èª¤'
          break
        case 'service-not-allowed':
          errorMessage = 'èªéŸ³æœå‹™ä¸å¯ç”¨'
          break
        case 'bad-grammar':
          errorMessage = 'èªæ³•éŒ¯èª¤'
          break
        default:
          errorMessage = `èªéŸ³è­˜åˆ¥éŒ¯èª¤: ${event.error}`
      }

      error.value = errorMessage
      emit('error', errorMessage)
    }

    speechRecognition.value.onend = () => {
      console.log('ğŸ¤ èªéŸ³è­˜åˆ¥çµæŸ')
      isListening.value = false
    }

    speechRecognition.value.onnomatch = () => {
      // å¯ä»¥é¸æ“‡æ˜¯å¦é¡¯ç¤ºç„¡åŒ¹é…è¨Šæ¯
    }

    return true
  } catch (err) {
    console.error('èªéŸ³è­˜åˆ¥åˆå§‹åŒ–å¤±æ•—:', err)
    error.value = 'èªéŸ³è­˜åˆ¥åˆå§‹åŒ–å¤±æ•—'
    emit('error', error.value)
    return false
  }
}

// é–‹å§‹éŒ„éŸ³
const startRecording = async () => {
  try {
    error.value = ''
    
    // Try Permissions API first to give clearer guidance on mobile
    try {
      const perms = (navigator as any).permissions
      if (perms && perms.query) {
        try {
          const status = await perms.query({ name: 'microphone' } as any)
          if (status.state === 'denied') {
            error.value = 'éº¥å…‹é¢¨æ¬Šé™å·²è¢«æ‹’çµ•ï¼Œè«‹åˆ°ç€è¦½å™¨è¨­å®šå…è¨±æœ¬ç¶²ç«™ä½¿ç”¨éº¥å…‹é¢¨'
            emit('error', error.value)
            console.warn('Microphone permission denied')
            return
          }
          // if 'prompt' or 'granted', continue to request getUserMedia
        } catch (e) {
          // Permissions API may not support 'microphone' on some browsers; ignore
          console.debug('Permissions API microphone query not available or failed', e)
        }
      }
    } catch (e) {
      console.debug('Permissions API not available', e)
    }

    const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
    
    mediaRecorder.value = new MediaRecorder(stream)
    
    mediaRecorder.value.onstop = () => {
      // åœæ­¢æ‰€æœ‰éŸ³è»Œ
      stream.getTracks().forEach(track => track.stop())
    }
    
    mediaRecorder.value.start()
    isRecording.value = true
    recordingTime.value = 0
    
    // é–‹å§‹èªéŸ³è­˜åˆ¥
    if (speechRecognition.value) {
      // ç¢ºä¿èªéŸ³è­˜åˆ¥å¯¦ä¾‹æ­£ç¢ºåˆå§‹åŒ–
      try {
        speechRecognition.value.start()
      } catch (error) {
        console.warn('èªéŸ³è­˜åˆ¥å•Ÿå‹•å¤±æ•—ï¼Œå˜—è©¦é‡æ–°åˆå§‹åŒ–:', error)
        // å¦‚æœå•Ÿå‹•å¤±æ•—ï¼Œé‡æ–°åˆå§‹åŒ–ä¸¦é‡è©¦
        initializeSpeechRecognition()
        setTimeout(() => {
          if (speechRecognition.value) {
            speechRecognition.value.start()
          }
        }, 100)
      }
    }
    
    // é–‹å§‹è¨ˆæ™‚
    recordingInterval.value = window.setInterval(() => {
      recordingTime.value++
    }, 1000)
    
    emit('recordingStart')
    props.onRecordingStart?.()
    
    // æˆåŠŸé–‹å§‹éŒ„éŸ³å¾Œéš±è—ç§»å‹•è¨­å‚™æŒ‡å¼•
    if (showMobileGuidance.value) {
      showMobileGuidance.value = false
    }
    
  } catch (err) {
    // Provide more actionable messages for mobile Chrome
    const msg = (err && (err as any).name) ? (err as any).name : String(err)
    if (msg === 'NotAllowedError' || msg === 'SecurityError') {
      error.value = 'éº¥å…‹é¢¨æ¬Šé™è¢«æ‹’çµ•ï¼šè«‹åœ¨ç€è¦½å™¨æˆ–ç³»çµ±è¨­å®šä¸­å…è¨±éº¥å…‹é¢¨ä½¿ç”¨ï¼ˆéœ€ HTTPSï¼‰'
    } else if (msg === 'NotFoundError' || msg === 'OverconstrainedError') {
      error.value = 'æœªæ‰¾åˆ°éº¥å…‹é¢¨è£ç½®ï¼Œè«‹ç¢ºèªè£ç½®æœ‰å¯ç”¨çš„éº¥å…‹é¢¨'
    } else if (msg === 'NotReadableError') {
      error.value = 'ç„¡æ³•è®€å–éº¥å…‹é¢¨ï¼Œè«‹ç¢ºèªå…¶ä»–æ‡‰ç”¨ç¨‹å¼æœªå ç”¨éº¥å…‹é¢¨'
    } else {
      error.value = 'ç„¡æ³•è¨ªå•éº¥å…‹é¢¨ï¼Œè«‹æª¢æŸ¥æ¬Šé™è¨­å®šèˆ‡ç€è¦½å™¨è¨­å®š'
    }
    emit('error', error.value)
    console.error('éŒ„éŸ³éŒ¯èª¤:', err)
  }
}

// åœæ­¢éŒ„éŸ³
const stopRecording = () => {
  if (mediaRecorder.value && isRecording.value) {
    mediaRecorder.value.stop()
    isRecording.value = false
    
    // åœæ­¢èªéŸ³è­˜åˆ¥
    if (speechRecognition.value) {
      speechRecognition.value.stop()
    }
    
    if (recordingInterval.value) {
      clearInterval(recordingInterval.value)
      recordingInterval.value = null
    }
    
    emit('recordingStop')
    props.onRecordingStop?.()
  }
}

// åˆ‡æ›éŒ„éŸ³ç‹€æ…‹
const toggleRecording = () => {
  if (isRecording.value) {
    stopRecording()
  } else {
    startRecording()
  }
}

// æ¸…ç†è³‡æº
const cleanup = () => {
  if (recordingInterval.value) {
    clearInterval(recordingInterval.value)
  }
  if (speechRecognition.value) {
    speechRecognition.value.abort()
  }
}

// æª¢æ¸¬æ˜¯å¦ç‚ºç§»å‹•è¨­å‚™
const isMobileDevice = () => {
  return /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent) ||
         (navigator.maxTouchPoints && navigator.maxTouchPoints > 2)
}

onMounted(() => {
  // æª¢æŸ¥æ˜¯å¦åœ¨ HTTPS ç’°å¢ƒä¸‹ï¼ˆç§»å‹•è¨­å‚™éœ€è¦ï¼‰
  if (location.protocol !== 'https:' && location.hostname !== 'localhost') {
    error.value = 'èªéŸ³åŠŸèƒ½éœ€è¦ HTTPS ç’°å¢ƒï¼Œè«‹ä½¿ç”¨ HTTPS è¨ªå•'
    emit('error', error.value)
    return
  }
  
  // å¦‚æœæ˜¯ç§»å‹•è¨­å‚™ï¼Œé¡¯ç¤ºä½¿ç”¨æŒ‡å¼• - å·²é—œé–‰
  // if (isMobileDevice()) {
  //   showMobileGuidance.value = true
  // }
  
  // åˆå§‹åŒ–èªéŸ³è­˜åˆ¥
  const success = initializeSpeechRecognition()
  if (!success) {
    console.warn('èªéŸ³è­˜åˆ¥åˆå§‹åŒ–å¤±æ•—')
  }
})

onUnmounted(() => {
  cleanup()
})
</script>
